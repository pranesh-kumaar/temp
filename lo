import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from tensorflow import keras
from tensorflow.keras import layers

# Load your dataset here
# Assuming you have 'data.csv' with columns ['feature1', 'feature2', ..., 'feature22', 'signal']

# Load data and split into features and labels
data = pd.read_csv('data.csv')
features = data.iloc[:, :22].values
labels = data['signal'].values

# Normalize the features
scaler = StandardScaler()
features = scaler.fit_transform(features)

# Prepare input data with 14 days previous data
window_size = 14
X = []
y = []

for i in range(window_size, len(features)):
    X.append(features[i-window_size:i])
    y.append(labels[i])

X = np.array(X)
y = np.array(y)

# Build the neural network model
model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=(window_size, 22)),
    layers.Dense(32, activation='relu'),
    layers.Dense(1, activation='tanh') # tanh activation to output values in the range [-1, 1]
])

# Compile the model
model.compile(optimizer='adam', loss='mse')

# Train the model
model.fit(X, y, epochs=100, batch_size=32, verbose=0)

# Now, you can use the trained model to predict trade signals
# To get predictions for a new dataset 'new_data', you can preprocess it and then use:
# new_features = new_data.iloc[:, :22].values
# new_features = scaler.transform(new_features)
# X_new = []
# for i in range(window_size, len(new_features)):
#     X_new.append(new_features[i-window_size:i])
# X_new = np.array(X_new)
# predictions = model.predict(X_new)

# 'predictions' will contain the predicted signals for the new data.