import neat
import numpy as np
import tensorflow as tf
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Layer

class LTCCell(Layer):
    def __init__(self, units, **kwargs):
        self.units = units
        self.state_size = units
        super(LTCCell, self).__init__(**kwargs)

    def build(self, input_shape):
        input_dim = input_shape[-1]
        self.kernel = self.add_weight(shape=(input_dim, self.units),
                                      initializer='glorot_uniform',
                                      name='kernel')
        self.recurrent_kernel = self.add_weight(
            shape=(self.units, self.units),
            initializer='orthogonal',
            name='recurrent_kernel')
        self.built = True

    def call(self, inputs, states):
        prev_output = states[0]
        h = K.dot(inputs, self.kernel)
        output = h + K.dot(prev_output, self.recurrent_kernel)
        return output, [output]

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Assuming your dataset is loaded and stored in X_train and y_train
# X_train should be a 3D array with shape (number of samples, 14, 26)
data = df.drop(['Open', 'Close', 'High', 'Low'], axis=1)
X_train = []
i = 0
for x in range(0, len(data) - 14):
    y = data.iloc[i:i + 14]
    X_train.append(y.values)
    i = i + 1

X_train = np.array(X_train)

dfy = df['Signal'].iloc[14:].values
y_train = []
for x in dfy:
    y_train.append(x + 1)

y_train = np.array(y_train)

# Define the fitness function
def eval_genomes(genomes, config):
    for genome_id, genome in genomes:
        net = neat.nn.FeedForwardNetwork.create(genome, config)
        genome.fitness = 0
        for xi, xo in zip(X_train, y_train):
            output = net.activate(xi.flatten())
            genome.fitness -= (output[0] - xo) ** 2

# Load configuration file
config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,
                     neat.DefaultSpeciesSet, neat.DefaultStagnation,
                     'config-feedforward')

# Create the population
p = neat.Population(config)

# Add reporters
p.add_reporter(neat.StdOutReporter(True))
stats = neat.StatisticsReporter()
p.add_reporter(stats)

# Run the genetic algorithm
winner = p.run(eval_genomes, 50)

# Create the winning network
winner_net = neat.nn.FeedForwardNetwork.create(winner, config)

# Assuming you have test data stored in X_test (3D array with shape (number of samples, 14, 26))
X_test = []
i = 0
for x in range(0, len(data.iloc[:236]) - 14):
    y = data.iloc[i:i + 14]
    X_test.append(y.values)
    i = i + 1

X_test = np.array(X_test)

# Get predictions on test data
predictions = []
for xi in X_test:
    output = winner_net.activate(xi.flatten())
    predictions.append(output[0])
trade_signals = np.argmax(predictions, axis=1) - 1  # Convert predicted probabilities to trade signals (-1, 0, 1)

backtest_data['Signal'] = trade_signals

from backtesting import Backtest, Strategy

class SignalStrategy(Strategy):
    def init(self):
        pass
    
    def next(self):
        global index
        index = []
        current_signal = self.data.Signal[-1]
        if current_signal == 1:
            if not self.position:
                self.buy()
        elif current_signal == -1:
            if self.position:
                self.position.close()
                
bt = Backtest(backtest_data, SignalStrategy, cash=10_000)
stats = bt.run()

bt.plot()
print(stats[6]) #stats[6] gives the returns
